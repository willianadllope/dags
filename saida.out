+ enviando algumas planilhas para a Penhorate com dados de cenarios e produtos para analise de pautas
+ limitando a memoria do SQL da maquina cockpitwebsql, para usar 80% do limite, deixando 20% pro Windows
+ usei o S3 como storage para envia as informacoes entre o Snowflake e o RDS em Postgresql, 
	entao para fazer a conversao do encoding utf-8 para iso8859-1 estou tentando montar uma funcao no lambda que Ã© disparada
	toda vez que chega um arquivo nesse bucket, converte o encode e grava num novo bucket. Entao o RDS passaria a ler desse novo bucket.

Ã“timo! Vamos adaptar o cÃ³digo para que a funÃ§Ã£o Lambda seja **acionada automaticamente** quando um novo arquivo for adicionado ao bucket S3. Isso exige:

1. **Configurar um gatilho S3** no Lambda.
2. **Ajustar o cÃ³digo Lambda para extrair informaÃ§Ãµes do evento.**
3. **Criar uma polÃ­tica de IAM apropriada.**

---

### âœ… 1. CÃ³digo Lambda adaptado para evento do S3

```python
import boto3
import urllib.parse

s3 = boto3.client('s3')

def lambda_handler(event, context):
    # Extrair informaÃ§Ãµes do evento
    bucket_origem = event['Records'][0]['s3']['bucket']['name']
    chave_arquivo = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])
    
    # Nome do bucket de destino (pode ser o mesmo ou outro)
    bucket_destino = 'meu-bucket-destino'
    chave_destino = f'{chave_arquivo.rsplit(".", 1)[0]}_iso.txt'  # opcional: renomear

    try:
        # Baixar o arquivo
        response = s3.get_object(Bucket=bucket_origem, Key=chave_arquivo)
        conteudo_utf8 = response['Body'].read().decode('utf-8')

        # Converter para ISO-8859-1
        conteudo_iso = conteudo_utf8.encode('iso-8859-1', errors='replace')

        # Enviar para bucket de destino
        s3.put_object(
            Bucket=bucket_destino,
            Key=chave_destino,
            Body=conteudo_iso,
            ContentType='text/plain; charset=iso-8859-1'
        )

        return {
            'statusCode': 200,
            'body': f'Arquivo convertido: {bucket_destino}/{chave_destino}'
        }

    except Exception as e:
        print(f"Erro ao processar {chave_arquivo} do bucket {bucket_origem}. Erro: {e}")
        raise e
```

---

### âœ… 2. PolÃ­tica de IAM (anexar Ã  role da funÃ§Ã£o Lambda)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::meu-bucket-origem/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject"
      ],
      "Resource": "arn:aws:s3:::meu-bucket-destino/*"
    }
  ]
}
```

---

### âœ… 3. Adicionar gatilho S3 Ã  funÃ§Ã£o Lambda

No console AWS Lambda:

1. VÃ¡ atÃ© sua funÃ§Ã£o Lambda.
2. Clique em **"Adicionar gatilho"**.
3. Selecione **S3**.
4. Escolha o bucket de origem.
5. Tipo de evento: **PUT** (ou seja, novos arquivos).
6. Prefixo/sufixo se quiser filtrar (ex: `"uploads/"`, `".txt"`).

---

Se vocÃª quiser, posso te ajudar com um template completo do Terraform ou AWS SAM para automatizar tudo. Quer seguir por esse caminho?

-------------
Perfeito! Vamos usar o **AWS SAM (Serverless Application Model)**, que Ã© uma forma prÃ¡tica e oficial de implantar funÃ§Ãµes Lambda com infraestrutura como cÃ³digo. Ele usa o CloudFormation por baixo dos panos.

---

## ðŸ§© Estrutura do Projeto

```
utf8-to-iso88591/
â”‚
â”œâ”€â”€ template.yaml            # Template SAM
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app.py               # CÃ³digo Lambda
â””â”€â”€ requirements.txt         # (opcional, nÃ£o necessÃ¡rio neste caso)
```

---

## âœ… `template.yaml` (SAM Template)

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: Lambda que converte arquivos UTF-8 para ISO-8859-1 ao serem enviados ao S3

Globals:
  Function:
    Timeout: 30
    Runtime: python3.12
    MemorySize: 128

Resources:
  Utf8ToIsoFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: app.lambda_handler
      CodeUri: src/
      Policies:
        - Statement:
            - Effect: Allow
              Action:
                - s3:GetObject
              Resource: arn:aws:s3:::meu-bucket-origem/*
            - Effect: Allow
              Action:
                - s3:PutObject
              Resource: arn:aws:s3:::meu-bucket-destino/*
      Events:
        S3FileUpload:
          Type: S3
          Properties:
            Bucket: meu-bucket-origem
            Events: s3:ObjectCreated:Put
            Filter:
              S3Key:
                Rules:
                  - Name: suffix
                    Value: .txt
```

---

## âœ… `src/app.py` (CÃ³digo da Lambda)

```python
import boto3
import urllib.parse

s3 = boto3.client('s3')

def lambda_handler(event, context):
    bucket_origem = event['Records'][0]['s3']['bucket']['name']
    chave_arquivo = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])

    bucket_destino = 'meu-bucket-destino'
    chave_destino = f'{chave_arquivo.rsplit(".", 1)[0]}_iso.txt'

    try:
        response = s3.get_object(Bucket=bucket_origem, Key=chave_arquivo)
        conteudo_utf8 = response['Body'].read().decode('utf-8')
        conteudo_iso = conteudo_utf8.encode('iso-8859-1', errors='replace')

        s3.put_object(
            Bucket=bucket_destino,
            Key=chave_destino,
            Body=conteudo_iso,
            ContentType='text/plain; charset=iso-8859-1'
        )

        return {
            'statusCode': 200,
            'body': f'Arquivo convertido com sucesso: {chave_destino}'
        }

    except Exception as e:
        print(f"Erro: {e}")
        raise
```

---

## âœ… Como implantar com SAM

1. **Instale o AWS SAM CLI**:

   ```bash
   brew install aws/tap/aws-sam-cli  # macOS
   ```

2. **Empacote e implante**:

   ```bash
   sam build
   sam deploy --guided
   ```

   No `--guided`, ele vai perguntar:

   * Nome do stack CloudFormation
   * RegiÃ£o
   * Buckets
   * ConfirmaÃ§Ãµes de permissÃµes

---

Se vocÃª quiser, posso gerar esse projeto como um `.zip` ou fornecer comandos para rodar localmente com `sam local`. Deseja isso?


